{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (6.2.1)\n",
      "\u001b[33mWARNING: You are using pip version 19.2.3, however version 19.3.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: gdown in /usr/local/lib/python3.6/dist-packages (3.8.3)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from gdown) (4.39.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from gdown) (2.22.0)\n",
      "Requirement already satisfied: six in /usr/lib/python3/dist-packages (from gdown) (1.11.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from gdown) (3.0.12)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->gdown) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->gdown) (1.25.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->gdown) (2019.11.28)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /usr/lib/python3/dist-packages (from requests->gdown) (2.6)\n",
      "\u001b[33mWARNING: You are using pip version 19.2.3, however version 19.3.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install Pillow\n",
    "!pip install gdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import tensorflow as tf\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "import IPython.display as display\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import gdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.debugging.set_log_device_placement(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.0'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/device:GPU:0'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.gpu_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy = tf.distribute.MirroredStrategy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  2\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tf/combined_data\n",
      "/tf\n"
     ]
    }
   ],
   "source": [
    "import pathlib\n",
    "\n",
    "data_dir = %pwd\n",
    "data_dir = data_dir + '/combined_data'\n",
    "data_dir = pathlib.Path(data_dir)\n",
    "print(data_dir)\n",
    "test_dir = %pwd\n",
    "print(test_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11122\n"
     ]
    }
   ],
   "source": [
    "image_count = len(list(data_dir.glob('*/*.jpg')))\n",
    "print(image_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['benign', 'malignant'], dtype='<U9')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CLASS_NAMES = np.array([item.name for item in data_dir.glob('*') if item.name != \"retrained_labels.txt\"])\n",
    "CLASS_NAMES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The 1./255 is to convert from uint8 to float32 in range [0,1].\n",
    "BATCH_SIZE_PER_REPLICA = 64\n",
    "BATCH_SIZE = BATCH_SIZE_PER_REPLICA * strategy.num_replicas_in_sync\n",
    "\n",
    "IMG_HEIGHT = 256\n",
    "IMG_WIDTH = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_batch(image_batch, label_batch):\n",
    "  plt.figure(figsize=(10,10))\n",
    "  for n in range(25):\n",
    "      ax = plt.subplot(5,5,n+1)\n",
    "      plt.imshow(image_batch[n])\n",
    "      plt.title(CLASS_NAMES[label_batch[n]==1][0].title())\n",
    "      plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import PIL.Image\n",
    "image_batch, label_batch = next(train_data_gen)\n",
    "show_batch(image_batch, label_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing op MatchingFiles in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Shape in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op StridedSlice in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Greater in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op ReduceJoin in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Add in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op TensorSliceDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Shape in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op StridedSlice in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Maximum in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op AnonymousRandomSeedGenerator in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ShuffleDatasetV2 in device /job:localhost/replica:0/task:0/device:CPU:0\n"
     ]
    }
   ],
   "source": [
    "list_ds = tf.data.Dataset.list_files(str(data_dir/'*/*'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tf/combined_data/benign/SOB_B_A-14-22549CD-40-022.jpg\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "#transform the images broek out by the text files are in converted to a list of images similar to those read in from list_ds\n",
    "with open('train_list.txt', 'r') as f:\n",
    "        train_list = []\n",
    "        for line in f:\n",
    "            line = line.rstrip('\\n')\n",
    "            line= line.replace('data', 'tf', 1)\n",
    "            train_list.append(line)        \n",
    "        #train_list = [tf.strings.split(x, '/')[:-1] for x in train_list]\n",
    "        \n",
    "        \n",
    "\n",
    "with open('test_list.txt', 'r') as f:\n",
    "        test_list = []\n",
    "        for line in f:\n",
    "            line = line.rstrip('\\n')\n",
    "            line= line.replace('data', 'tf', 1)\n",
    "            test_list.append(line)        \n",
    "        #test_list = [tf.strings.split(x, '/')[-1] for x in test_list]\n",
    "        \n",
    "with open('val_list.txt', 'r') as f:\n",
    "        val_list = []\n",
    "        for line in f:\n",
    "            line = line.rstrip('\\n')\n",
    "            line= line.replace('data', 'tf', 1)\n",
    "            val_list.append(line)        \n",
    "        #val_list = [tf.strings.split(x, '/')[-1] for x in val_list]  \n",
    "print(train_list[0])\n",
    "print(type(train_list[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op AnonymousIteratorV2 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op MakeIterator in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op IteratorGetNextSync in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op DeleteIterator in device /job:localhost/replica:0/task:0/device:CPU:0\n"
     ]
    }
   ],
   "source": [
    "#simple verification that the images taken from the text files are actually in the folder we read the files in from the list_ds\n",
    "#input\n",
    "count = 0\n",
    "for x in list_ds:\n",
    "    \n",
    "    #print(train_list[0])\n",
    "    if (str(x.numpy())[2:-1]) in train_list:\n",
    "        continue\n",
    "    elif (str(x.numpy())[2:-1]) in val_list:\n",
    "        continue\n",
    "    elif (str(x.numpy())[2:-1]) in test_list:\n",
    "        continue\n",
    "    else:\n",
    "        count += 1\n",
    "        print(str(x.numpy())[2:-1])\n",
    "        print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices(train_list)\n",
    "valid_dataset = tf.data.Dataset.from_tensor_slices(val_list)\n",
    "test_dataset  = tf.data.Dataset.from_tensor_slices(test_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Picture Size = 8837\n",
      "Valid Picture Size = 1144\n",
      "Test Picture Size =  1141\n",
      "11122\n"
     ]
    }
   ],
   "source": [
    "# set the shuflle and steps per epochs based on size\n",
    "train_size = len(list(train_dataset))\n",
    "print('Train Picture Size = ' + str(train_size))\n",
    "\n",
    "valid_size = len(list(valid_dataset))\n",
    "print('Valid Picture Size = ' + str(valid_size))\n",
    "\n",
    "test_size = len(list(test_dataset))\n",
    "print('Test Picture Size =  ' + str(test_size))\n",
    "\n",
    "print(test_size + train_size + valid_size)\n",
    "\n",
    "train_shuffle_size = train_size\n",
    "valid_shuffle_size = valid_size\n",
    "test_shuffle_size = test_size\n",
    "STEPS_PER_EPOCH = np.ceil(train_size/BATCH_SIZE)\n",
    "VALID_STEPS_PER_EPOCH = np.ceil(valid_size/BATCH_SIZE)\n",
    "TEST_STEPS_PER_EPOCH = np.ceil(test_size/BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing op TakeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "b'/tf/combined_data/benign/SOB_B_A-14-22549CD-40-022.jpg'\n",
      "b'/tf/combined_data/benign/1.3.6.1.4.1.9590.100.1.2.204433294712596606213536280693657707372_1-283.jpg'\n",
      "b'/tf/combined_data/benign/SOB_B_A-14-22549AB-200-010.jpg'\n",
      "b'/tf/combined_data/benign/SOB_B_TA-14-3411F-40-006.jpg'\n",
      "b'/tf/combined_data/benign/SOB_B_TA-14-21978AB-40-014.jpg'\n",
      "b'/tf/combined_data/benign/1.3.6.1.4.1.9590.100.1.2.216820283213818005421900437772111995033_1-005.jpg'\n",
      "b'/tf/combined_data/benign/1.3.6.1.4.1.9590.100.1.2.381280286813484985622860668700998869999_1-179.jpg'\n",
      "b'/tf/combined_data/benign/1.3.6.1.4.1.9590.100.1.2.8224011612206957419584270413389091077_1-222.jpg'\n",
      "b'/tf/combined_data/benign/1.3.6.1.4.1.9590.100.1.2.316699245610247354328827790532537478140_1-239.jpg'\n",
      "b'/tf/combined_data/benign/1.3.6.1.4.1.9590.100.1.2.81224121613615658336040014641017971693_1-239.jpg'\n",
      "b'/tf/combined_data/benign/1.3.6.1.4.1.9590.100.1.2.190592923311432132100233908851180999464_1-063.jpg'\n",
      "b'/tf/combined_data/benign/SOB_B_F-14-23060AB-40-004.jpg'\n",
      "b'/tf/combined_data/benign/1.3.6.1.4.1.9590.100.1.2.25530538411839768118282182472795553760_1-087.jpg'\n",
      "b'/tf/combined_data/benign/1.3.6.1.4.1.9590.100.1.2.84979282111169186110355127162031674632_1-018.jpg'\n",
      "b'/tf/combined_data/benign/SOB_B_F-14-21998EF-100-024.jpg'\n"
     ]
    }
   ],
   "source": [
    "for f in train_dataset.take(5):\n",
    "  print(f.numpy())\n",
    "\n",
    "for f in valid_dataset.take(5):\n",
    "  print(f.numpy())\n",
    "\n",
    "for f in test_dataset.take(5):\n",
    "  print(f.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n"
     ]
    }
   ],
   "source": [
    "def get_label(file_path):\n",
    "  # convert the path to a list of path components\n",
    "    # use '/' for linux\n",
    "  parts = tf.strings.split(file_path, '/')\n",
    "  # The second to last is the class-directory\n",
    "  return parts[-2] == CLASS_NAMES\n",
    "\n",
    "def decode_img(img):\n",
    "  # convert the compressed string to a 3D uint8 tensor\n",
    "  img = tf.image.decode_jpeg(img, channels=3)\n",
    "  # Use `convert_image_dtype` to convert to floats in the [0,1] range.\n",
    "  img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "  # resize the image to the desired size.\n",
    "  return tf.image.resize(img, [IMG_WIDTH, IMG_HEIGHT])\n",
    "\n",
    "def process_path(file_path):\n",
    "  label = get_label(file_path)\n",
    "  # load the raw data from the file as a string\n",
    "  img = tf.io.read_file(file_path)\n",
    "  img = decode_img(img)\n",
    "  return img, label\n",
    "\n",
    "# Set `num_parallel_calls` so multiple images are loaded/processed in parallel.\n",
    "train_labeled_ds = train_dataset.map(process_path, num_parallel_calls=AUTOTUNE)\n",
    "valid_labeled_ds = valid_dataset.map(process_path, num_parallel_calls=AUTOTUNE)\n",
    "test_labeled_ds = test_dataset.map(process_path, num_parallel_calls=AUTOTUNE)\n",
    "\n",
    "#see https://www.tensorflow.org/tutorials/load_data/images for above and cells above taken from there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing op TakeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op AnonymousIteratorV2 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op IteratorGetNextSync in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Image shape:  (256, 256, 3)\n",
      "Label:  [ True False]\n",
      "Image shape:  (256, 256, 3)\n",
      "Label:  [ True False]\n",
      "Image shape:  (256, 256, 3)\n",
      "Label:  [ True False]\n",
      "Image shape:  (256, 256, 3)\n",
      "Label:  [ True False]\n",
      "Image shape:  (256, 256, 3)\n",
      "Label:  [ True False]\n",
      "Image shape:  (256, 256, 3)\n",
      "Label:  [ True False]\n",
      "Image shape:  (256, 256, 3)\n",
      "Label:  [ True False]\n",
      "Image shape:  (256, 256, 3)\n",
      "Label:  [ True False]\n",
      "Image shape:  (256, 256, 3)\n",
      "Label:  [ True False]\n",
      "Image shape:  (256, 256, 3)\n",
      "Label:  [ True False]\n",
      "(256, 256, 3)\n"
     ]
    }
   ],
   "source": [
    "#verify images and labels are joined.\n",
    "\n",
    "for image, label in train_labeled_ds.take(5):\n",
    "  print(\"Image shape: \", image.numpy().shape)\n",
    "  print(\"Label: \", label.numpy())\n",
    "  \n",
    "    \n",
    "  inputshape = image.numpy().shape\n",
    "\n",
    "for image, label in test_labeled_ds.take(5):\n",
    "  \n",
    "  print(\"Image shape: \", image.numpy().shape)\n",
    "  print(\"Label: \", label.numpy())\n",
    "  inputshape = image.numpy().shape\n",
    "  \n",
    "print(inputshape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<TakeDataset shapes: ((256, 256, 3), (2,)), types: (tf.float32, tf.bool)>\n",
      "<TakeDataset shapes: ((256, 256, 3), (2,)), types: (tf.float32, tf.bool)>\n",
      "<TakeDataset shapes: ((256, 256, 3), (2,)), types: (tf.float32, tf.bool)>\n"
     ]
    }
   ],
   "source": [
    "print(train_labeled_ds.take(1))\n",
    "print(test_labeled_ds.take(1))\n",
    "test2 = test_labeled_ds.take(1)\n",
    "print(test2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_transformation(image, label):\n",
    "    image = tf.image.random_flip_up_down(image)\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    image = tf.image.random_jpeg_quality(image, min_jpeg_quality=75, max_jpeg_quality=100)\n",
    "    #image = tf.image.random_brightness(image, max_delta=.2)\n",
    "    return image, label\n",
    "\n",
    "def prepare_for_training(ds, shuffle_buffer_size, cache=False):\n",
    "  # This is a small dataset, only load it once, and keep it in memory.\n",
    "  # use `.cache(filename)` to cache preprocessing work for datasets that don't\n",
    "  # fit in memory.\n",
    "  if cache:\n",
    "    if isinstance(cache, str):\n",
    "      ds = ds.cache(cache)\n",
    "    else:\n",
    "      ds = ds.cache()\n",
    "  ds = ds.map(image_transformation, num_parallel_calls=AUTOTUNE)\n",
    "\n",
    "  ds = ds.shuffle(buffer_size=shuffle_buffer_size)\n",
    "\n",
    "  # Repeat forever\n",
    "  ds = ds.repeat()\n",
    "\n",
    "  ds = ds.batch(BATCH_SIZE)\n",
    "\n",
    "  # `prefetch` lets the dataset fetch batches in the background while the model\n",
    "  # is training.\n",
    "  ds = ds.prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "  return ds\n",
    "\n",
    "#the above mostly constructed from TensorFlow tutorial:\n",
    "#https://www.tensorflow.org/tutorials/load_data/images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ShuffleDatasetV2 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op RepeatDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op BatchDatasetV2 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n"
     ]
    }
   ],
   "source": [
    "test1 = prepare_for_training(train_labeled_ds, train_shuffle_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "image_batch, label_batch = next(iter(test1))\n",
    "#image_batch, label_batch = train_ds.take(5)\n",
    "show_batch(image_batch.numpy(), label_batch.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-9b7876751b20>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mActivation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDropout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFlatten\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mConv2D\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMaxPool2D\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0moptimizers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'keras'"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential \n",
    "from keras.layers import Dense, Activation, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPool2D\n",
    "from keras import optimizers \n",
    "from keras.layers.advanced_activations import LeakyReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:1\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:1\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:1\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:1\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:1\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:1\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:1\n"
     ]
    }
   ],
   "source": [
    "#Building a CNN with 1 convulutional layer, an actication layer, a pooling layer then flatten to go into the fully connected\n",
    "# layer\n",
    "with strategy.scope():\n",
    "    model = tf.keras.Sequential([\n",
    "            tf.keras.layers.Conv2D(100, kernel_size = (3,3), input_shape = (IMG_WIDTH, IMG_HEIGHT, 3)),\n",
    "            tf.keras.layers.LeakyReLU(alpha=0.1),\n",
    "            tf.keras.layers.MaxPooling2D((2,2), padding='same'),\n",
    "            tf.keras.layers.Dropout(0.2),\n",
    "            tf.keras.layers.Conv2D(50, kernel_size = (5,5)),\n",
    "            tf.keras.layers.LeakyReLU(alpha=0.1),\n",
    "            tf.keras.layers.MaxPooling2D((2,2), padding='same'),\n",
    "            tf.keras.layers.Dropout(0.2),\n",
    "            tf.keras.layers.Conv2D(25, kernel_size = (5,5)),\n",
    "            tf.keras.layers.LeakyReLU(alpha=0.1),\n",
    "            tf.keras.layers.MaxPooling2D((2,2), padding='same'),\n",
    "            tf.keras.layers.Dropout(0.2),\n",
    "            tf.keras.layers.Conv2D(15, kernel_size = (3,3)),\n",
    "            tf.keras.layers.LeakyReLU(alpha=0.1),\n",
    "            tf.keras.layers.MaxPooling2D((2,2), padding='same'),\n",
    "            tf.keras.layers.Dropout(0.2),\n",
    "            tf.keras.layers.Conv2D(5, kernel_size = (3,3)),\n",
    "            tf.keras.layers.LeakyReLU(alpha=0.1),\n",
    "            tf.keras.layers.MaxPooling2D((2,2), padding='same'),\n",
    "            tf.keras.layers.Dropout(0.2),\n",
    "            tf.keras.layers.Flatten(),\n",
    "            tf.keras.layers.Dense(128),\n",
    "            tf.keras.layers.LeakyReLU(alpha=0.1),\n",
    "            tf.keras.layers.Dense(2, activation = 'softmax')])\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                    optimizer='adam',\n",
    "                    metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1575382953.3294265\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "print(time())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Train for 70.0 steps, validate for 9.0 steps\n",
      "Epoch 1/200\n",
      "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:1\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:1\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:1\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:1\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:1\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:1\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:1\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:1\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:1\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:1\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:1\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:1\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:1\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:1\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:1\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:1\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:1\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:1\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:1\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:1\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:1\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:1\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:1\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:1\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:1\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:1\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:1\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:1\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:1\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:1\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:1\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:1\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:1\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:1\n",
      "Executing op __inference_initialize_variables_172609 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op __inference_distributed_function_173777 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "69/70 [============================>.] - ETA: 4s - loss: 0.5778 - accuracy: 0.6872Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:1\n",
      "Executing op __inference_distributed_function_174491 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "70/70 [==============================] - 358s 5s/step - loss: 0.5773 - accuracy: 0.6884 - val_loss: 0.6218 - val_accuracy: 0.7465\n",
      "Epoch 2/200\n",
      "70/70 [==============================] - 201s 3s/step - loss: 0.5276 - accuracy: 0.7383 - val_loss: 0.5387 - val_accuracy: 0.7405\n",
      "Epoch 3/200\n",
      "70/70 [==============================] - 202s 3s/step - loss: 0.5173 - accuracy: 0.7422 - val_loss: 0.5822 - val_accuracy: 0.6797\n",
      "Epoch 4/200\n",
      "70/70 [==============================] - 207s 3s/step - loss: 0.5190 - accuracy: 0.7456 - val_loss: 0.5171 - val_accuracy: 0.7240\n",
      "Epoch 5/200\n",
      "70/70 [==============================] - 204s 3s/step - loss: 0.5035 - accuracy: 0.7494 - val_loss: 0.5090 - val_accuracy: 0.7370\n",
      "Epoch 6/200\n",
      "70/70 [==============================] - 191s 3s/step - loss: 0.4982 - accuracy: 0.7496 - val_loss: 0.5104 - val_accuracy: 0.7561\n",
      "Epoch 7/200\n",
      "70/70 [==============================] - 186s 3s/step - loss: 0.4871 - accuracy: 0.7633 - val_loss: 0.5012 - val_accuracy: 0.7578\n",
      "Epoch 8/200\n",
      "70/70 [==============================] - 192s 3s/step - loss: 0.4966 - accuracy: 0.7545 - val_loss: 0.5102 - val_accuracy: 0.7648\n",
      "Epoch 9/200\n",
      "70/70 [==============================] - 187s 3s/step - loss: 0.4761 - accuracy: 0.7693 - val_loss: 0.5120 - val_accuracy: 0.7509\n",
      "Epoch 10/200\n",
      "70/70 [==============================] - 187s 3s/step - loss: 0.4817 - accuracy: 0.7627 - val_loss: 0.4971 - val_accuracy: 0.7622\n",
      "Epoch 11/200\n",
      "70/70 [==============================] - 184s 3s/step - loss: 0.4800 - accuracy: 0.7631 - val_loss: 0.4875 - val_accuracy: 0.7639\n",
      "Epoch 12/200\n",
      "70/70 [==============================] - 188s 3s/step - loss: 0.4759 - accuracy: 0.7680 - val_loss: 0.4823 - val_accuracy: 0.7639\n",
      "Epoch 13/200\n",
      "70/70 [==============================] - 188s 3s/step - loss: 0.4867 - accuracy: 0.7569 - val_loss: 0.4878 - val_accuracy: 0.7708\n",
      "Epoch 14/200\n",
      "70/70 [==============================] - 186s 3s/step - loss: 0.4883 - accuracy: 0.7586 - val_loss: 0.4968 - val_accuracy: 0.7378\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/200\n",
      "70/70 [==============================] - 188s 3s/step - loss: 0.4729 - accuracy: 0.7599 - val_loss: 0.4872 - val_accuracy: 0.7578\n",
      "Epoch 16/200\n",
      "70/70 [==============================] - 187s 3s/step - loss: 0.4620 - accuracy: 0.7714 - val_loss: 0.4840 - val_accuracy: 0.7717\n",
      "Epoch 17/200\n",
      "70/70 [==============================] - 190s 3s/step - loss: 0.4611 - accuracy: 0.7742 - val_loss: 0.5370 - val_accuracy: 0.7370\n",
      "Epoch 18/200\n",
      "70/70 [==============================] - 189s 3s/step - loss: 0.4641 - accuracy: 0.7744 - val_loss: 0.4912 - val_accuracy: 0.7622\n",
      "Epoch 19/200\n",
      "70/70 [==============================] - 186s 3s/step - loss: 0.4604 - accuracy: 0.7756 - val_loss: 0.4918 - val_accuracy: 0.7700\n",
      "Epoch 20/200\n",
      "70/70 [==============================] - 188s 3s/step - loss: 0.4419 - accuracy: 0.7858 - val_loss: 0.4748 - val_accuracy: 0.7795\n",
      "Epoch 21/200\n",
      "70/70 [==============================] - 187s 3s/step - loss: 0.4514 - accuracy: 0.7798 - val_loss: 0.4718 - val_accuracy: 0.7717\n",
      "Epoch 22/200\n",
      "70/70 [==============================] - 188s 3s/step - loss: 0.4579 - accuracy: 0.7699 - val_loss: 0.4872 - val_accuracy: 0.7587\n",
      "Epoch 23/200\n",
      "70/70 [==============================] - 185s 3s/step - loss: 0.4438 - accuracy: 0.7804 - val_loss: 0.4483 - val_accuracy: 0.7726\n",
      "Epoch 24/200\n",
      "70/70 [==============================] - 187s 3s/step - loss: 0.4316 - accuracy: 0.7874 - val_loss: 0.4387 - val_accuracy: 0.7873\n",
      "Epoch 25/200\n",
      "70/70 [==============================] - 184s 3s/step - loss: 0.4554 - accuracy: 0.7781 - val_loss: 0.4490 - val_accuracy: 0.7769\n",
      "Epoch 26/200\n",
      "70/70 [==============================] - 183s 3s/step - loss: 0.4300 - accuracy: 0.7907 - val_loss: 0.4384 - val_accuracy: 0.7786\n",
      "Epoch 27/200\n",
      "70/70 [==============================] - 187s 3s/step - loss: 0.4150 - accuracy: 0.7859 - val_loss: 0.4331 - val_accuracy: 0.7891\n",
      "Epoch 28/200\n",
      "70/70 [==============================] - 185s 3s/step - loss: 0.4194 - accuracy: 0.7888 - val_loss: 0.4100 - val_accuracy: 0.8012\n",
      "Epoch 29/200\n",
      "70/70 [==============================] - 184s 3s/step - loss: 0.4205 - accuracy: 0.7844 - val_loss: 0.4447 - val_accuracy: 0.7639\n",
      "Epoch 30/200\n",
      "70/70 [==============================] - 188s 3s/step - loss: 0.4256 - accuracy: 0.7882 - val_loss: 0.4332 - val_accuracy: 0.7899\n",
      "Epoch 31/200\n",
      "70/70 [==============================] - 189s 3s/step - loss: 0.4118 - accuracy: 0.7922 - val_loss: 0.4228 - val_accuracy: 0.7908\n",
      "Epoch 32/200\n",
      "70/70 [==============================] - 188s 3s/step - loss: 0.4032 - accuracy: 0.7973 - val_loss: 0.4019 - val_accuracy: 0.7995\n",
      "Epoch 33/200\n",
      "70/70 [==============================] - 185s 3s/step - loss: 0.4095 - accuracy: 0.7954 - val_loss: 0.4460 - val_accuracy: 0.7856\n",
      "Epoch 34/200\n",
      "70/70 [==============================] - 184s 3s/step - loss: 0.4065 - accuracy: 0.7968 - val_loss: 0.4106 - val_accuracy: 0.8056\n",
      "Epoch 35/200\n",
      "70/70 [==============================] - 186s 3s/step - loss: 0.4008 - accuracy: 0.7990 - val_loss: 0.4085 - val_accuracy: 0.7908\n",
      "Epoch 36/200\n",
      "70/70 [==============================] - 185s 3s/step - loss: 0.4023 - accuracy: 0.7984 - val_loss: 0.4051 - val_accuracy: 0.7986\n",
      "Epoch 37/200\n",
      "70/70 [==============================] - 183s 3s/step - loss: 0.3975 - accuracy: 0.7978 - val_loss: 0.4063 - val_accuracy: 0.8030\n",
      "Epoch 38/200\n",
      "70/70 [==============================] - 186s 3s/step - loss: 0.3955 - accuracy: 0.8010 - val_loss: 0.4086 - val_accuracy: 0.7865\n",
      "Epoch 39/200\n",
      "70/70 [==============================] - 187s 3s/step - loss: 0.3844 - accuracy: 0.8036 - val_loss: 0.4164 - val_accuracy: 0.7899\n",
      "Epoch 40/200\n",
      "70/70 [==============================] - 186s 3s/step - loss: 0.3850 - accuracy: 0.8110 - val_loss: 0.4103 - val_accuracy: 0.8012\n",
      "Epoch 41/200\n",
      "70/70 [==============================] - 186s 3s/step - loss: 0.3900 - accuracy: 0.7971 - val_loss: 0.4202 - val_accuracy: 0.7882\n",
      "Epoch 42/200\n",
      "70/70 [==============================] - 188s 3s/step - loss: 0.3797 - accuracy: 0.8092 - val_loss: 0.3966 - val_accuracy: 0.7986\n",
      "Epoch 43/200\n",
      "70/70 [==============================] - 187s 3s/step - loss: 0.3785 - accuracy: 0.8083 - val_loss: 0.3895 - val_accuracy: 0.7943\n",
      "Epoch 44/200\n",
      "70/70 [==============================] - 187s 3s/step - loss: 0.3741 - accuracy: 0.8080 - val_loss: 0.4087 - val_accuracy: 0.7995\n",
      "Epoch 45/200\n",
      "70/70 [==============================] - 190s 3s/step - loss: 0.3788 - accuracy: 0.8042 - val_loss: 0.3622 - val_accuracy: 0.8142\n",
      "Epoch 46/200\n",
      "70/70 [==============================] - 188s 3s/step - loss: 0.3814 - accuracy: 0.8033 - val_loss: 0.3940 - val_accuracy: 0.7977\n",
      "Epoch 47/200\n",
      "70/70 [==============================] - 184s 3s/step - loss: 0.3706 - accuracy: 0.8094 - val_loss: 0.3735 - val_accuracy: 0.8073\n",
      "Epoch 48/200\n",
      "70/70 [==============================] - 186s 3s/step - loss: 0.3735 - accuracy: 0.8078 - val_loss: 0.3686 - val_accuracy: 0.8160\n",
      "Epoch 49/200\n",
      "70/70 [==============================] - 182s 3s/step - loss: 0.3792 - accuracy: 0.8060 - val_loss: 0.4096 - val_accuracy: 0.7986\n",
      "Epoch 50/200\n",
      "70/70 [==============================] - 184s 3s/step - loss: 0.3698 - accuracy: 0.8104 - val_loss: 0.4309 - val_accuracy: 0.8003\n",
      "Epoch 51/200\n",
      "70/70 [==============================] - 183s 3s/step - loss: 0.3690 - accuracy: 0.8074 - val_loss: 0.3820 - val_accuracy: 0.8073\n",
      "Epoch 52/200\n",
      "70/70 [==============================] - 184s 3s/step - loss: 0.3632 - accuracy: 0.8117 - val_loss: 0.3514 - val_accuracy: 0.8151\n",
      "Epoch 53/200\n",
      "70/70 [==============================] - 188s 3s/step - loss: 0.3654 - accuracy: 0.8143 - val_loss: 0.3779 - val_accuracy: 0.8047\n",
      "Epoch 54/200\n",
      "70/70 [==============================] - 186s 3s/step - loss: 0.3742 - accuracy: 0.8077 - val_loss: 0.3583 - val_accuracy: 0.8220\n",
      "Epoch 55/200\n",
      "70/70 [==============================] - 188s 3s/step - loss: 0.3622 - accuracy: 0.8131 - val_loss: 0.4139 - val_accuracy: 0.7943\n",
      "Epoch 56/200\n",
      "70/70 [==============================] - 186s 3s/step - loss: 0.3638 - accuracy: 0.8161 - val_loss: 0.3596 - val_accuracy: 0.8281\n",
      "Epoch 57/200\n",
      "70/70 [==============================] - 186s 3s/step - loss: 0.3530 - accuracy: 0.8176 - val_loss: 0.3862 - val_accuracy: 0.7969\n",
      "Epoch 58/200\n",
      "70/70 [==============================] - 189s 3s/step - loss: 0.3562 - accuracy: 0.8135 - val_loss: 0.3504 - val_accuracy: 0.8125\n",
      "Epoch 59/200\n",
      "70/70 [==============================] - 189s 3s/step - loss: 0.3532 - accuracy: 0.8138 - val_loss: 0.3882 - val_accuracy: 0.7995\n",
      "Epoch 60/200\n",
      "70/70 [==============================] - 187s 3s/step - loss: 0.3458 - accuracy: 0.8229 - val_loss: 0.3607 - val_accuracy: 0.8090\n",
      "Epoch 61/200\n",
      "70/70 [==============================] - 191s 3s/step - loss: 0.3461 - accuracy: 0.8220 - val_loss: 0.3566 - val_accuracy: 0.8194\n",
      "Epoch 62/200\n",
      "70/70 [==============================] - 189s 3s/step - loss: 0.3566 - accuracy: 0.8170 - val_loss: 0.3823 - val_accuracy: 0.8047\n",
      "Epoch 63/200\n",
      "70/70 [==============================] - 198s 3s/step - loss: 0.3691 - accuracy: 0.8154 - val_loss: 0.4175 - val_accuracy: 0.7865\n",
      "Epoch 64/200\n",
      "70/70 [==============================] - 189s 3s/step - loss: 0.3559 - accuracy: 0.8172 - val_loss: 0.3937 - val_accuracy: 0.8082\n",
      "Epoch 65/200\n",
      "70/70 [==============================] - 189s 3s/step - loss: 0.3581 - accuracy: 0.8202 - val_loss: 0.3849 - val_accuracy: 0.8064\n",
      "Epoch 66/200\n",
      "70/70 [==============================] - 191s 3s/step - loss: 0.3507 - accuracy: 0.8223 - val_loss: 0.3901 - val_accuracy: 0.8168\n",
      "Epoch 67/200\n",
      "70/70 [==============================] - 189s 3s/step - loss: 0.3532 - accuracy: 0.8151 - val_loss: 0.3834 - val_accuracy: 0.7891\n",
      "Epoch 68/200\n",
      "70/70 [==============================] - 190s 3s/step - loss: 0.3493 - accuracy: 0.8218 - val_loss: 0.4354 - val_accuracy: 0.8021\n",
      "Epoch 69/200\n",
      "70/70 [==============================] - 188s 3s/step - loss: 0.3485 - accuracy: 0.8184 - val_loss: 0.3551 - val_accuracy: 0.8125\n",
      "Epoch 70/200\n",
      "70/70 [==============================] - 188s 3s/step - loss: 0.3358 - accuracy: 0.8266 - val_loss: 0.3768 - val_accuracy: 0.8099\n",
      "Epoch 71/200\n",
      "70/70 [==============================] - 195s 3s/step - loss: 0.3586 - accuracy: 0.8166 - val_loss: 0.3612 - val_accuracy: 0.8108\n",
      "Epoch 72/200\n",
      "70/70 [==============================] - 193s 3s/step - loss: 0.3489 - accuracy: 0.8229 - val_loss: 0.3407 - val_accuracy: 0.8116\n",
      "Epoch 73/200\n",
      "70/70 [==============================] - 189s 3s/step - loss: 0.3424 - accuracy: 0.8217 - val_loss: 0.3743 - val_accuracy: 0.8082\n",
      "Epoch 74/200\n",
      "70/70 [==============================] - 187s 3s/step - loss: 0.3395 - accuracy: 0.8203 - val_loss: 0.3737 - val_accuracy: 0.8142\n",
      "Epoch 75/200\n",
      "70/70 [==============================] - 189s 3s/step - loss: 0.3397 - accuracy: 0.8218 - val_loss: 0.3957 - val_accuracy: 0.7951\n",
      "Epoch 76/200\n",
      "70/70 [==============================] - 187s 3s/step - loss: 0.3379 - accuracy: 0.8227 - val_loss: 0.3629 - val_accuracy: 0.8125\n",
      "Epoch 77/200\n",
      "70/70 [==============================] - 192s 3s/step - loss: 0.3323 - accuracy: 0.8289 - val_loss: 0.3669 - val_accuracy: 0.8047\n",
      "Epoch 78/200\n",
      "70/70 [==============================] - 180s 3s/step - loss: 0.3458 - accuracy: 0.8203 - val_loss: 0.3502 - val_accuracy: 0.8186\n",
      "Epoch 79/200\n",
      "70/70 [==============================] - 192s 3s/step - loss: 0.3373 - accuracy: 0.8253 - val_loss: 0.3513 - val_accuracy: 0.8142\n",
      "Epoch 80/200\n",
      "70/70 [==============================] - 188s 3s/step - loss: 0.3425 - accuracy: 0.8231 - val_loss: 0.3669 - val_accuracy: 0.8194\n",
      "Epoch 81/200\n",
      "70/70 [==============================] - 193s 3s/step - loss: 0.3317 - accuracy: 0.8263 - val_loss: 0.3495 - val_accuracy: 0.8177\n",
      "Epoch 82/200\n",
      "70/70 [==============================] - 186s 3s/step - loss: 0.3388 - accuracy: 0.8288 - val_loss: 0.3245 - val_accuracy: 0.8203\n",
      "Epoch 83/200\n",
      "70/70 [==============================] - 183s 3s/step - loss: 0.3457 - accuracy: 0.8210 - val_loss: 0.3828 - val_accuracy: 0.7977\n",
      "Epoch 84/200\n",
      "70/70 [==============================] - 185s 3s/step - loss: 0.3330 - accuracy: 0.8234 - val_loss: 0.3458 - val_accuracy: 0.8212\n",
      "Epoch 85/200\n",
      "70/70 [==============================] - 186s 3s/step - loss: 0.3404 - accuracy: 0.8248 - val_loss: 0.4151 - val_accuracy: 0.8151\n",
      "Epoch 86/200\n",
      "70/70 [==============================] - 188s 3s/step - loss: 0.3300 - accuracy: 0.8318 - val_loss: 0.3353 - val_accuracy: 0.8229\n",
      "Epoch 87/200\n",
      "70/70 [==============================] - 187s 3s/step - loss: 0.3239 - accuracy: 0.8333 - val_loss: 0.3322 - val_accuracy: 0.8116\n",
      "Epoch 88/200\n",
      "70/70 [==============================] - 187s 3s/step - loss: 0.3316 - accuracy: 0.8271 - val_loss: 0.3830 - val_accuracy: 0.8082\n",
      "Epoch 89/200\n",
      "70/70 [==============================] - 194s 3s/step - loss: 0.3277 - accuracy: 0.8289 - val_loss: 0.3361 - val_accuracy: 0.8212\n",
      "Epoch 90/200\n",
      "70/70 [==============================] - 179s 3s/step - loss: 0.3259 - accuracy: 0.8306 - val_loss: 0.3465 - val_accuracy: 0.8220\n",
      "Epoch 91/200\n",
      "70/70 [==============================] - 187s 3s/step - loss: 0.3319 - accuracy: 0.8301 - val_loss: 0.3421 - val_accuracy: 0.8264\n",
      "Epoch 92/200\n",
      "70/70 [==============================] - 189s 3s/step - loss: 0.3233 - accuracy: 0.8330 - val_loss: 0.3278 - val_accuracy: 0.8220\n",
      "Epoch 93/200\n",
      "70/70 [==============================] - 187s 3s/step - loss: 0.3169 - accuracy: 0.8342 - val_loss: 0.3274 - val_accuracy: 0.8238\n",
      "Epoch 94/200\n",
      "70/70 [==============================] - 185s 3s/step - loss: 0.3305 - accuracy: 0.8289 - val_loss: 0.3761 - val_accuracy: 0.8012\n",
      "Epoch 95/200\n",
      "70/70 [==============================] - 187s 3s/step - loss: 0.3236 - accuracy: 0.8278 - val_loss: 0.3457 - val_accuracy: 0.8160\n",
      "Epoch 96/200\n",
      "70/70 [==============================] - 184s 3s/step - loss: 0.3307 - accuracy: 0.8252 - val_loss: 0.3437 - val_accuracy: 0.8056\n",
      "Epoch 97/200\n",
      "70/70 [==============================] - 187s 3s/step - loss: 0.3200 - accuracy: 0.8330 - val_loss: 0.3683 - val_accuracy: 0.8151\n",
      "Epoch 98/200\n",
      "70/70 [==============================] - 186s 3s/step - loss: 0.3378 - accuracy: 0.8239 - val_loss: 0.3723 - val_accuracy: 0.8030\n",
      "Epoch 99/200\n",
      "70/70 [==============================] - 186s 3s/step - loss: 0.3244 - accuracy: 0.8288 - val_loss: 0.3610 - val_accuracy: 0.8082\n",
      "Epoch 100/200\n",
      "70/70 [==============================] - 185s 3s/step - loss: 0.3234 - accuracy: 0.8296 - val_loss: 0.3357 - val_accuracy: 0.8255\n",
      "Epoch 101/200\n",
      "70/70 [==============================] - 186s 3s/step - loss: 0.3217 - accuracy: 0.8339 - val_loss: 0.3762 - val_accuracy: 0.8047\n",
      "Epoch 102/200\n",
      "70/70 [==============================] - 184s 3s/step - loss: 0.3226 - accuracy: 0.8302 - val_loss: 0.3628 - val_accuracy: 0.8160\n",
      "Epoch 103/200\n",
      "70/70 [==============================] - 187s 3s/step - loss: 0.3215 - accuracy: 0.8349 - val_loss: 0.3423 - val_accuracy: 0.8203\n",
      "Epoch 104/200\n",
      "70/70 [==============================] - 189s 3s/step - loss: 0.3317 - accuracy: 0.8270 - val_loss: 0.3404 - val_accuracy: 0.8134\n",
      "Epoch 105/200\n",
      "70/70 [==============================] - 189s 3s/step - loss: 0.3174 - accuracy: 0.8364 - val_loss: 0.4119 - val_accuracy: 0.7934\n",
      "Epoch 106/200\n",
      "70/70 [==============================] - 187s 3s/step - loss: 0.3196 - accuracy: 0.8348 - val_loss: 0.3280 - val_accuracy: 0.8125\n",
      "Epoch 107/200\n",
      "70/70 [==============================] - 188s 3s/step - loss: 0.3177 - accuracy: 0.8350 - val_loss: 0.3340 - val_accuracy: 0.8333\n",
      "Epoch 108/200\n",
      "70/70 [==============================] - 185s 3s/step - loss: 0.3123 - accuracy: 0.8342 - val_loss: 0.3675 - val_accuracy: 0.8168\n",
      "Epoch 109/200\n",
      "70/70 [==============================] - 187s 3s/step - loss: 0.3146 - accuracy: 0.8359 - val_loss: 0.3557 - val_accuracy: 0.8168\n",
      "Epoch 110/200\n",
      "70/70 [==============================] - 186s 3s/step - loss: 0.3197 - accuracy: 0.8374 - val_loss: 0.3375 - val_accuracy: 0.8212\n",
      "Epoch 111/200\n",
      "70/70 [==============================] - 186s 3s/step - loss: 0.3120 - accuracy: 0.8395 - val_loss: 0.3545 - val_accuracy: 0.8247\n",
      "Epoch 112/200\n",
      "70/70 [==============================] - 187s 3s/step - loss: 0.2985 - accuracy: 0.8413 - val_loss: 0.3414 - val_accuracy: 0.8255\n",
      "Epoch 113/200\n",
      "70/70 [==============================] - 184s 3s/step - loss: 0.3136 - accuracy: 0.8373 - val_loss: 0.3440 - val_accuracy: 0.8151\n",
      "Epoch 114/200\n",
      "70/70 [==============================] - 186s 3s/step - loss: 0.3149 - accuracy: 0.8362 - val_loss: 0.3245 - val_accuracy: 0.8359\n",
      "Epoch 115/200\n",
      "70/70 [==============================] - 188s 3s/step - loss: 0.3179 - accuracy: 0.8369 - val_loss: 0.3266 - val_accuracy: 0.8273\n",
      "Epoch 116/200\n",
      "70/70 [==============================] - 189s 3s/step - loss: 0.3007 - accuracy: 0.8408 - val_loss: 0.3319 - val_accuracy: 0.8307\n",
      "Epoch 117/200\n",
      "70/70 [==============================] - 191s 3s/step - loss: 0.3114 - accuracy: 0.8358 - val_loss: 0.3149 - val_accuracy: 0.8212\n",
      "Epoch 118/200\n",
      "70/70 [==============================] - 188s 3s/step - loss: 0.3055 - accuracy: 0.8442 - val_loss: 0.3513 - val_accuracy: 0.8108\n",
      "Epoch 119/200\n",
      "70/70 [==============================] - 184s 3s/step - loss: 0.3204 - accuracy: 0.8306 - val_loss: 0.3333 - val_accuracy: 0.8220\n",
      "Epoch 120/200\n",
      "70/70 [==============================] - 184s 3s/step - loss: 0.3079 - accuracy: 0.8365 - val_loss: 0.3428 - val_accuracy: 0.8168\n",
      "Epoch 121/200\n",
      "70/70 [==============================] - 182s 3s/step - loss: 0.3029 - accuracy: 0.8395 - val_loss: 0.3485 - val_accuracy: 0.8177\n",
      "Epoch 122/200\n",
      "70/70 [==============================] - 182s 3s/step - loss: 0.3302 - accuracy: 0.8325 - val_loss: 0.3712 - val_accuracy: 0.8047\n",
      "Epoch 123/200\n",
      "70/70 [==============================] - 183s 3s/step - loss: 0.3035 - accuracy: 0.8483 - val_loss: 0.3541 - val_accuracy: 0.8082\n",
      "Epoch 124/200\n",
      "70/70 [==============================] - 185s 3s/step - loss: 0.2988 - accuracy: 0.8431 - val_loss: 0.3445 - val_accuracy: 0.8134\n",
      "Epoch 125/200\n",
      "70/70 [==============================] - 184s 3s/step - loss: 0.2985 - accuracy: 0.8436 - val_loss: 0.3133 - val_accuracy: 0.8394\n",
      "Epoch 126/200\n",
      "70/70 [==============================] - 187s 3s/step - loss: 0.3055 - accuracy: 0.8420 - val_loss: 0.3124 - val_accuracy: 0.8368\n",
      "Epoch 127/200\n",
      "70/70 [==============================] - 189s 3s/step - loss: 0.3090 - accuracy: 0.8382 - val_loss: 0.3987 - val_accuracy: 0.8021\n",
      "Epoch 128/200\n",
      "70/70 [==============================] - 191s 3s/step - loss: 0.3020 - accuracy: 0.8416 - val_loss: 0.3323 - val_accuracy: 0.8134\n",
      "Epoch 129/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70/70 [==============================] - 187s 3s/step - loss: 0.3062 - accuracy: 0.8410 - val_loss: 0.3382 - val_accuracy: 0.8194\n",
      "Epoch 130/200\n",
      "70/70 [==============================] - 190s 3s/step - loss: 0.3087 - accuracy: 0.8392 - val_loss: 0.3478 - val_accuracy: 0.8229\n",
      "Epoch 131/200\n",
      "70/70 [==============================] - 189s 3s/step - loss: 0.2999 - accuracy: 0.8442 - val_loss: 0.3190 - val_accuracy: 0.8229\n",
      "Epoch 132/200\n",
      "70/70 [==============================] - 190s 3s/step - loss: 0.3047 - accuracy: 0.8405 - val_loss: 0.3325 - val_accuracy: 0.8290\n",
      "Epoch 133/200\n",
      "70/70 [==============================] - 192s 3s/step - loss: 0.2952 - accuracy: 0.8460 - val_loss: 0.3253 - val_accuracy: 0.8229\n",
      "Epoch 134/200\n",
      "70/70 [==============================] - 188s 3s/step - loss: 0.2957 - accuracy: 0.8422 - val_loss: 0.3342 - val_accuracy: 0.8273\n",
      "Epoch 135/200\n",
      "70/70 [==============================] - 195s 3s/step - loss: 0.3023 - accuracy: 0.8411 - val_loss: 0.3036 - val_accuracy: 0.8290\n",
      "Epoch 136/200\n",
      "70/70 [==============================] - 192s 3s/step - loss: 0.2924 - accuracy: 0.8451 - val_loss: 0.3385 - val_accuracy: 0.8229\n",
      "Epoch 137/200\n",
      "70/70 [==============================] - 189s 3s/step - loss: 0.2992 - accuracy: 0.8401 - val_loss: 0.3075 - val_accuracy: 0.8325\n",
      "Epoch 138/200\n",
      "70/70 [==============================] - 187s 3s/step - loss: 0.3067 - accuracy: 0.8372 - val_loss: 0.3254 - val_accuracy: 0.8238\n",
      "Epoch 139/200\n",
      "70/70 [==============================] - 191s 3s/step - loss: 0.2928 - accuracy: 0.8434 - val_loss: 0.3379 - val_accuracy: 0.8177\n",
      "Epoch 140/200\n",
      "70/70 [==============================] - 190s 3s/step - loss: 0.3140 - accuracy: 0.8408 - val_loss: 0.3222 - val_accuracy: 0.8220\n",
      "Epoch 141/200\n",
      "70/70 [==============================] - 191s 3s/step - loss: 0.3067 - accuracy: 0.8419 - val_loss: 0.3449 - val_accuracy: 0.8194\n",
      "Epoch 142/200\n",
      "70/70 [==============================] - 190s 3s/step - loss: 0.2906 - accuracy: 0.8471 - val_loss: 0.3510 - val_accuracy: 0.8134\n",
      "Epoch 143/200\n",
      "70/70 [==============================] - 188s 3s/step - loss: 0.2990 - accuracy: 0.8424 - val_loss: 0.3296 - val_accuracy: 0.8247\n",
      "Epoch 144/200\n",
      "70/70 [==============================] - 192s 3s/step - loss: 0.3009 - accuracy: 0.8440 - val_loss: 0.3569 - val_accuracy: 0.8168\n",
      "Epoch 145/200\n",
      "70/70 [==============================] - 189s 3s/step - loss: 0.3084 - accuracy: 0.8408 - val_loss: 0.3178 - val_accuracy: 0.8299\n",
      "Epoch 146/200\n",
      "70/70 [==============================] - 186s 3s/step - loss: 0.2909 - accuracy: 0.8453 - val_loss: 0.3363 - val_accuracy: 0.8142\n",
      "Epoch 147/200\n",
      "70/70 [==============================] - 190s 3s/step - loss: 0.2890 - accuracy: 0.8479 - val_loss: 0.3273 - val_accuracy: 0.8082\n",
      "Epoch 148/200\n",
      "70/70 [==============================] - 188s 3s/step - loss: 0.2905 - accuracy: 0.8456 - val_loss: 0.3312 - val_accuracy: 0.8351\n",
      "Epoch 149/200\n",
      "70/70 [==============================] - 189s 3s/step - loss: 0.2853 - accuracy: 0.8484 - val_loss: 0.3313 - val_accuracy: 0.8281\n",
      "Epoch 150/200\n",
      "70/70 [==============================] - 190s 3s/step - loss: 0.2973 - accuracy: 0.8435 - val_loss: 0.3130 - val_accuracy: 0.8299\n",
      "Epoch 151/200\n",
      "70/70 [==============================] - 187s 3s/step - loss: 0.2939 - accuracy: 0.8453 - val_loss: 0.3175 - val_accuracy: 0.8247\n",
      "Epoch 152/200\n",
      "70/70 [==============================] - 183s 3s/step - loss: 0.2899 - accuracy: 0.8487 - val_loss: 0.3210 - val_accuracy: 0.8229\n",
      "Epoch 153/200\n",
      "70/70 [==============================] - 196s 3s/step - loss: 0.2894 - accuracy: 0.8518 - val_loss: 0.3143 - val_accuracy: 0.8368\n",
      "Epoch 154/200\n",
      "70/70 [==============================] - 188s 3s/step - loss: 0.2955 - accuracy: 0.8456 - val_loss: 0.3257 - val_accuracy: 0.8316\n",
      "Epoch 155/200\n",
      "70/70 [==============================] - 188s 3s/step - loss: 0.2926 - accuracy: 0.8494 - val_loss: 0.3144 - val_accuracy: 0.8342\n",
      "Epoch 156/200\n",
      "70/70 [==============================] - 186s 3s/step - loss: 0.2969 - accuracy: 0.8452 - val_loss: 0.3114 - val_accuracy: 0.8273\n",
      "Epoch 157/200\n",
      "70/70 [==============================] - 189s 3s/step - loss: 0.2910 - accuracy: 0.8480 - val_loss: 0.3144 - val_accuracy: 0.8220\n",
      "Epoch 158/200\n",
      "70/70 [==============================] - 188s 3s/step - loss: 0.2994 - accuracy: 0.8479 - val_loss: 0.3094 - val_accuracy: 0.8299\n",
      "Epoch 159/200\n",
      "70/70 [==============================] - 188s 3s/step - loss: 0.2940 - accuracy: 0.8487 - val_loss: 0.3419 - val_accuracy: 0.8255\n",
      "Epoch 160/200\n",
      "70/70 [==============================] - 186s 3s/step - loss: 0.2969 - accuracy: 0.8478 - val_loss: 0.3213 - val_accuracy: 0.8429\n",
      "Epoch 161/200\n",
      "70/70 [==============================] - 185s 3s/step - loss: 0.2941 - accuracy: 0.8484 - val_loss: 0.3436 - val_accuracy: 0.8212\n",
      "Epoch 162/200\n",
      "70/70 [==============================] - 187s 3s/step - loss: 0.2821 - accuracy: 0.8530 - val_loss: 0.3202 - val_accuracy: 0.8273\n",
      "Epoch 163/200\n",
      "70/70 [==============================] - 186s 3s/step - loss: 0.2855 - accuracy: 0.8494 - val_loss: 0.3174 - val_accuracy: 0.8325\n",
      "Epoch 164/200\n",
      "70/70 [==============================] - 187s 3s/step - loss: 0.2913 - accuracy: 0.8471 - val_loss: 0.3028 - val_accuracy: 0.8281\n",
      "Epoch 165/200\n",
      "70/70 [==============================] - 186s 3s/step - loss: 0.2887 - accuracy: 0.8499 - val_loss: 0.3110 - val_accuracy: 0.8333\n",
      "Epoch 166/200\n",
      "70/70 [==============================] - 184s 3s/step - loss: 0.2837 - accuracy: 0.8478 - val_loss: 0.3742 - val_accuracy: 0.8160\n",
      "Epoch 167/200\n",
      "70/70 [==============================] - 184s 3s/step - loss: 0.2858 - accuracy: 0.8508 - val_loss: 0.2940 - val_accuracy: 0.8316\n",
      "Epoch 168/200\n",
      "70/70 [==============================] - 185s 3s/step - loss: 0.2958 - accuracy: 0.8425 - val_loss: 0.3146 - val_accuracy: 0.8359\n",
      "Epoch 169/200\n",
      "70/70 [==============================] - 185s 3s/step - loss: 0.2774 - accuracy: 0.8502 - val_loss: 0.3365 - val_accuracy: 0.8220\n",
      "Epoch 170/200\n",
      "70/70 [==============================] - 184s 3s/step - loss: 0.2847 - accuracy: 0.8494 - val_loss: 0.3349 - val_accuracy: 0.8238\n",
      "Epoch 171/200\n",
      "70/70 [==============================] - 184s 3s/step - loss: 0.2833 - accuracy: 0.8560 - val_loss: 0.3441 - val_accuracy: 0.8281\n",
      "Epoch 172/200\n",
      "70/70 [==============================] - 184s 3s/step - loss: 0.2843 - accuracy: 0.8537 - val_loss: 0.3328 - val_accuracy: 0.8273\n",
      "Epoch 173/200\n",
      "70/70 [==============================] - 184s 3s/step - loss: 0.2906 - accuracy: 0.8498 - val_loss: 0.3178 - val_accuracy: 0.8281\n",
      "Epoch 174/200\n",
      "70/70 [==============================] - 183s 3s/step - loss: 0.2724 - accuracy: 0.8576 - val_loss: 0.3328 - val_accuracy: 0.8264\n",
      "Epoch 175/200\n",
      "70/70 [==============================] - 184s 3s/step - loss: 0.3007 - accuracy: 0.8480 - val_loss: 0.3189 - val_accuracy: 0.8273\n",
      "Epoch 176/200\n",
      "70/70 [==============================] - 184s 3s/step - loss: 0.2831 - accuracy: 0.8506 - val_loss: 0.3119 - val_accuracy: 0.8403\n",
      "Epoch 177/200\n",
      "70/70 [==============================] - 184s 3s/step - loss: 0.2694 - accuracy: 0.8592 - val_loss: 0.4217 - val_accuracy: 0.7847\n",
      "Epoch 178/200\n",
      "70/70 [==============================] - 184s 3s/step - loss: 0.2815 - accuracy: 0.8503 - val_loss: 0.3329 - val_accuracy: 0.8177\n",
      "Epoch 179/200\n",
      "70/70 [==============================] - 186s 3s/step - loss: 0.2960 - accuracy: 0.8475 - val_loss: 0.3218 - val_accuracy: 0.8307\n",
      "Epoch 180/200\n",
      "70/70 [==============================] - 186s 3s/step - loss: 0.2816 - accuracy: 0.8568 - val_loss: 0.3147 - val_accuracy: 0.8394\n",
      "Epoch 181/200\n",
      "70/70 [==============================] - 186s 3s/step - loss: 0.2969 - accuracy: 0.8503 - val_loss: 0.3062 - val_accuracy: 0.8394\n",
      "Epoch 182/200\n",
      "70/70 [==============================] - 186s 3s/step - loss: 0.2750 - accuracy: 0.8581 - val_loss: 0.3187 - val_accuracy: 0.8333\n",
      "Epoch 183/200\n",
      "70/70 [==============================] - 184s 3s/step - loss: 0.2869 - accuracy: 0.8499 - val_loss: 0.3739 - val_accuracy: 0.8177\n",
      "Epoch 184/200\n",
      "70/70 [==============================] - 187s 3s/step - loss: 0.2827 - accuracy: 0.8545 - val_loss: 0.3305 - val_accuracy: 0.8203\n",
      "Epoch 185/200\n",
      "70/70 [==============================] - 190s 3s/step - loss: 0.2798 - accuracy: 0.8558 - val_loss: 0.3392 - val_accuracy: 0.8108\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 186/200\n",
      "70/70 [==============================] - 185s 3s/step - loss: 0.2745 - accuracy: 0.8570 - val_loss: 0.3648 - val_accuracy: 0.8212\n",
      "Epoch 187/200\n",
      "70/70 [==============================] - 183s 3s/step - loss: 0.2828 - accuracy: 0.8555 - val_loss: 0.3226 - val_accuracy: 0.8368\n",
      "Epoch 188/200\n",
      "70/70 [==============================] - 182s 3s/step - loss: 0.2910 - accuracy: 0.8511 - val_loss: 0.3131 - val_accuracy: 0.8299\n",
      "Epoch 189/200\n",
      "70/70 [==============================] - 183s 3s/step - loss: 0.2740 - accuracy: 0.8542 - val_loss: 0.3042 - val_accuracy: 0.8333\n",
      "Epoch 190/200\n",
      "70/70 [==============================] - 183s 3s/step - loss: 0.2739 - accuracy: 0.8567 - val_loss: 0.3282 - val_accuracy: 0.8255\n",
      "Epoch 191/200\n",
      "70/70 [==============================] - 184s 3s/step - loss: 0.2749 - accuracy: 0.8571 - val_loss: 0.3428 - val_accuracy: 0.8116\n",
      "Epoch 192/200\n",
      "70/70 [==============================] - 184s 3s/step - loss: 0.2709 - accuracy: 0.8583 - val_loss: 0.3009 - val_accuracy: 0.8377\n",
      "Epoch 193/200\n",
      "70/70 [==============================] - 182s 3s/step - loss: 0.2707 - accuracy: 0.8577 - val_loss: 0.3487 - val_accuracy: 0.8168\n",
      "Epoch 194/200\n",
      "70/70 [==============================] - 182s 3s/step - loss: 0.2686 - accuracy: 0.8589 - val_loss: 0.3113 - val_accuracy: 0.8255\n",
      "Epoch 195/200\n",
      "70/70 [==============================] - 186s 3s/step - loss: 0.2846 - accuracy: 0.8482 - val_loss: 0.3450 - val_accuracy: 0.8281\n",
      "Epoch 196/200\n",
      "70/70 [==============================] - 189s 3s/step - loss: 0.2693 - accuracy: 0.8618 - val_loss: 0.3132 - val_accuracy: 0.8264\n",
      "Epoch 197/200\n",
      "70/70 [==============================] - 184s 3s/step - loss: 0.2735 - accuracy: 0.8575 - val_loss: 0.3398 - val_accuracy: 0.8220\n",
      "Epoch 198/200\n",
      "70/70 [==============================] - 188s 3s/step - loss: 0.2678 - accuracy: 0.8618 - val_loss: 0.3319 - val_accuracy: 0.8203\n",
      "Epoch 199/200\n",
      "70/70 [==============================] - 189s 3s/step - loss: 0.2907 - accuracy: 0.8487 - val_loss: 0.3027 - val_accuracy: 0.8403\n",
      "Epoch 200/200\n",
      "70/70 [==============================] - 187s 3s/step - loss: 0.2652 - accuracy: 0.8629 - val_loss: 0.3483 - val_accuracy: 0.8108\n",
      "627.2303589383761\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "model.fit(\n",
    "        prepare_for_training(train_labeled_ds, train_shuffle_size),\n",
    "        steps_per_epoch = STEPS_PER_EPOCH,\n",
    "        epochs = 200,\n",
    "        validation_data=prepare_for_training(valid_labeled_ds, valid_size),\n",
    "        validation_steps= VALID_STEPS_PER_EPOCH)\n",
    "\n",
    "end = time()\n",
    "\n",
    "print((end - start)/60) \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:1\n",
      "Executing op __inference_distributed_function_225459 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "9/9 [==============================] - 41s 5s/step - loss: 0.3044 - accuracy: 0.8438\n",
      "Test loss: 0.3044019175900353\n",
      "Test accuracy: 0.84375\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(prepare_for_training(test_labeled_ds, test_shuffle_size), steps = TEST_STEPS_PER_EPOCH, verbose=1)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#potential to save model if needed.\n",
    "model.save(\n",
    "    '/saved_model2/my6',\n",
    "    save_format='tf'    \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "References:\n",
    "https://stackoverflow.com/questions/51125266/how-do-i-split-tensorflow-datasets\n",
    "see paper for more references:\n",
    "Baseline CNN:  utlized the basis of many CNN from https://towardsdatascience.com/the-4-convolutional-neural-network-models-that-can-classify-your-fashion-images-9fe7f3e5399d, https://towardsdatascience.com/building-a-convolutional-neural-network-cnn-in-keras-329fbbadc5f5, tutorials in tensorflow.org such as https://www.tensorflow.org/guide/data, https://www.tensorflow.org/tutorials/load_data/images, https://www.tensorflow.org/guide/distributed_training, and https://www.tensorflow.org/guide/gpu.  Also, used articles from medium.com and towardsdatascience.com..  Also, used articles from medium.com and towardsdatascience.com.\n",
    "Also, used stackoverflow and other internet searches for understanding, trouble shooting, and general use.  Further context can be provided if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
